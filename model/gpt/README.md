# Large Language Model - Generative Pretrained Transformer (GPT)
<p align="middle">
<img src=https://github.com/dimashidayat99/Recomposing_Classical_Music_With_GAI/blob/main/model/gpt/framework/GPT_framework.png/>
</p>
<p align="middle">
    <em>Exploratory LSTM Framework.</em>
</p>

## Preprocessing
As shown in the framework figure above, the GPT modelling start with sampling process where only five midi file was used from Chopin composed music. All the midi files underwent the key tranposing process where all the key of the songs will be transpose to middle C. The midi files were processed further by extracting their parts. Each part was looked for their clef property where parts with treble clef property belongs to treble clef while parts with bass clef property belongs to bass clef. The music element such as notes, chords and durations will be extracted for each clef. The notes and chords are grouped together under the same feature while durations itself become another feature. Both features was combine forming a dataframe. There are total 2 dataframe which represent treble and bass clef. Both dataframe were processed further for data transformation, where list of chords were changed to chords label and numerical representation of duration data was transformed to categorical data. Noted that, in music, the duration is mostly represent as categorical representative instead of numerical representative. After transormation, both features of notes and durations were combined together forming a new features. This new feature (combined feature) is the only feature use for model training. The both dataframe later were encoded by using label encoding technique. Finally, the sequence data of each clef was produced by extracting 100 sequence data from the dataframe. The final product of the preprocessing stage is two data consist of 100 sequence of combined feature.

## Modelling 
This project used typically one model for each clef. Since there are two clef in total, therefore, there are total two identical model architecture were used for modelling stage. The architecture of GPT model start with input layer connected to embedding layers, the embedding layer which is a tranable vector embedding space is used to represent the discrete data as continous data in the form of vectors or embeddings and occupies a unique location in that space. Then, the positional encoding was added to the embedding vector to process the information of the data order. Then, three transformer block was linearly connected with the previous layer and the last layer of the GPT model is a dense layer with the neuron size of vocab size of combine features which give the final product of trained data. 

Each transformer block has similar architecture, where it contain multi head self attention connected linearly with dropout layer, layer normalization, feed forward network, another dropout layer and another layer normalization. The first component in the transformer block was multi head self attention which it allows the model to focus on different parts of the input sequence simultaneously by computing attention scores between different positions of the input. The outputs from different attention heads are concatenated and linearly transformed to retain information from different representation subspaces. The second layer, the dropout is a regularization technique that helps prevent overfitting by randomly setting a fraction of input units to zero during training. This encourages the network to learn more robust features and reduces reliance on specific neurons. Layer normalization normalizes the inputs of each layer to have a mean of zero and a standard deviation of one. This helps stabilize the training process and speeds up convergence. The feed foward network component consists of one or more fully connected layers with an activation function applied to the output of each layer. The feedforward network helps the model capture complex dependencies in the data. Another dropout layer was applied after the feedforward network to further regularize the model and prevent overfitting. Another layer normalization step aws applied after the second dropout layer to normalize the outputs of the feedforward network.


## Music Generation 
The outputs of GPT model are in the form of combined features (notes and durations). This output went through the top k sampling process where one from top ten of probability of combined feature was randomly select. The dataframe was constructed based on the selected value. Since there two clef, there are two total dataframe which are treble clef dataframe and bass clef dataframe. The dataframes underwent the inverse label encoding where the numerical representation of data will be transform to categorical data. The dataframe which contained only one feature which is the combine feature was splitted into two features for notes and durations. Each notes and durations were extracted from combined features to construct a new dataframe. The dataframe went through the inverse transformation to transform categorical representation of data to the initial data representation. The processed generated dataframes were submitted to the music stream, where the generated treble data was submitted to the treble clef stream while the generated bass data was submitted to the bass clef stream. Both streams went through the stream balancing process where the both streams length were adjusted to make sure both length are similar (or almost similar). The balanced streams were submitted to the music score. The music score was used to generate the music in the form of music audio and music sheet.
